# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dY7eM2ImqvrMUcg56Tkd5b7a9a-SD7YP

# Import and create functions
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import scipy.io as sio
import numpy as np
import tensorflow.keras as kr
import matplotlib.pyplot as plt
import IPython
import sys
from scipy.io.wavfile import write
import os, random
!pip install h5py pyyaml
# %matplotlib inline

# Commented out IPython magic to ensure Python compatibility.
inColab = True
if (inColab):
#   %tensorflow_version 2.x
  device_name = tf.test.gpu_device_name()
  if device_name != '/device:GPU:0':
    raise SystemError('GPU device not found')
  print('Found GPU at: {}'.format(device_name))

#normalize a signal 0 to 1
def normalize_0_1(x):
    return[(a+1)/2 for a in x]

#return a signal form 0 to 1 range to -1 to 1 range (normal audio range)
def invert_normalize_0_1(x):
    return [(a*2) - 1 for a in x]

#convert an array of values into a dataset matrix
def sequence_to_matrix(dataset, look_back=1):
    dataX = []
    for i in range(len(dataset)-look_back+1):
        a = dataset[i:(i+look_back)]
        dataX.append(a)
    return np.array(dataX)

#return the dataset matrix to an audio sequence
def matrix_to_sequence(matrix):
    n_samples = matrix.shape[0]
    n_steps = matrix.shape[1]
    seq_out = [0] * (n_samples-1 + n_steps)
    for i in range(n_samples):
        seq_out[i] = matrix[i,0]

    for i in range(1,n_steps):
        seq_out[n_samples-1+i] = matrix[n_samples-1,i]

    return seq_out

if inColab:
  from google.colab import drive
  drive.mount('/content/drive')
  data_path = '/content/drive/My Drive/TFG/Datasets and .py/'#data_path = '/content/drive/My Drive/'
  results_path = data_path + '/Results/'
  sys.path.append(data_path)
else:
  data_path = './'

"""# Hiperparametes"""

##############################################################______Hiperparametres_____#################################################################################

time_steps = 50                   #size of the time series (input sequence to the LSTM cells)
batch_size = 500                  #number of time series process in a forward or backward function
num_epochs = 30                   #number of times that the net process the whole dataset
fs = 44100                        #sample rate of the audios that we use
_val = fs * 10                    #number of samples uses to create the validation set                                       (input in secons_chosen * sample_rate )
_train = fs * 30                  #number of samples uses to create the training set                                         (input in secons_chosen * sample_rate )
start_val = fs * 60 * 5           #the first sample choosen in validation set                                                (input in minute_chosen * 60 * sample_rate )
start_train = fs * 60 * 14        #the first sample choosen in training set, must be far away from the validation            (input in minute_chosen * 60 * sample_rate )

"""# Reshaping of dataset"""

#charge the .mat files on dataset variables

load_small_DS = False #chose into a little version of the dataset or big
if (load_small_DS):
    fileNameTrain = 'training.mat' # 'trainLinea_MarshallMB15little.mat'             #dataset train/test path
    fileNameValidation = 'validation.mat' #'valLinea_MarshallMB15little.mat'         #dataset validation path
    training = sio.loadmat(data_path + fileNameTrain)['training']
    validation = sio.loadmat(data_path + fileNameValidation)['validation']
else:
    fileNameTrain = 'trainLinea_MarshallMB15.mat'                                    #dataset train/test path
    fileNameValidation = 'valLinea_MarshallMB15.mat'                                 #dataset validation path
    training = sio.loadmat(data_path + fileNameTrain,verify_compressed_data_integrity=False)['train']
    validation = sio.loadmat(data_path + fileNameValidation,verify_compressed_data_integrity=False)['train']

load_min_DS = True #set to True if you want to reduce the number of samples in the dataset.

if load_min_DS:
    dataset_size = _train
    max_train = dataset_size + time_steps + 1
    max_val = dataset_size//10 + time_steps + 1
else :
    max_train = training.shape[0] #(training.shape[0]//time_steps -1) * time_steps + 1
    max_val = validation.shape[0] #(validation.shape[0]//time_steps -1) * time_steps + 1

print(training.shape)
print(validation.shape)
max_val = _val

#perform the normalization of dataset to 0,1 range
do_normalize = True
if do_normalize:
    a = normalize_0_1(training[start_train:start_train+max_train,0])
    b = normalize_0_1(training[start_train:start_train+max_train,1])
    training = np.column_stack((a,b))

    a = normalize_0_1(validation[start_val:start_val+max_val,0])
    b = normalize_0_1(validation[start_val:start_val+max_val,1])
    validation = np.column_stack((a,b))
else:
    training = training[0:max_train,:]
    validation = validation[0:max_val,:]

print('training size:', training.shape)
print('validation size:', validation.shape)

#resize the audio sequence to time series matrix and adjust to the bach_size format

trainX = sequence_to_matrix(training[:,0], time_steps)
trainY = sequence_to_matrix(training[:,1], time_steps)
testX = sequence_to_matrix(validation[:,0], time_steps)
testY = sequence_to_matrix(validation[:,1], time_steps)
print(trainX.shape, trainY.shape, testX.shape, testY.shape)

#cut last frames to have a dataset divisible by time_steps (module zero).
#This is required bu the LSTM fitting function
size_data =  (trainX.shape[0]//batch_size -1) * batch_size
trainX = trainX[:size_data,:]
size_data =  (trainY.shape[0]//batch_size -1) * batch_size
trainY = trainY[0:size_data,:]

size_data =  (testX.shape[0]//batch_size -1) * batch_size
testX = testX[0:size_data,:]
size_data =  (testY.shape[0]//batch_size -1) * batch_size
testY = testY[0:size_data,:]

# reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))
testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))
print(trainX.shape, testX.shape)

#outputs shape should be [samples,]
print(trainY.shape, testY.shape)

"""# Creation and training of the RNN"""

#chose random number to seed of the code
def reset_random_seeds():
    os.environ['PYTHONHASHSEED']=str(1)
    tf.random.set_seed(1)
    np.random.seed(1)
    random.seed(1)

#create the RNN
#reset_random_seeds() #<-- this is only necessary if we want to replicate results.
tf.keras.backend.clear_session()
model = tf.keras.Sequential()
model.add(kr.layers.LSTM(10, batch_input_shape=( batch_size, time_steps, 1), stateful=True, return_sequences=True))
model.add(kr.layers.LSTM(10, batch_input_shape=(batch_size, time_steps, 1), stateful=True, return_sequences=True))
model.add(kr.layers.TimeDistributed(kr.layers.Dense(1, use_bias=False)))
model.add(kr.layers.BatchNormalization())
model.add(kr.layers.Activation("relu"))
model.compile(loss='mean_squared_error', optimizer='adam')
model.summary()

#the train function
h = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=num_epochs, batch_size=batch_size, verbose=1, shuffle=True)

#a function to save the weights after the train
model.save(data_path + 'path_to_my_model.h5')

#we can see the loss for ech epoch with hiperparametes chosen
plt.plot(h.history['loss'])
plt.plot(h.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
name = "time_steps {} batch_size {} epochs {} train {} s".format(time_steps, batch_size, num_epochs, np.floor(max_train/44100))
print(name)
plt.savefig(data_path + name+".png")

"""# Reshaping the output data, save the audios and plot the results"""

#predict in both sets after the training
testPredict = model.predict(testX, batch_size=batch_size)
trainPredict = model.predict(trainX, batch_size=batch_size)

#return to time the matrix sequence output of the net
trainPredict_seq = matrix_to_sequence(trainPredict)
testPredict_seq = matrix_to_sequence(testPredict)

#unnormalize the sequence
if do_normalize:
    trainPredict_seq = invert_normalize_0_1(trainPredict_seq)
    testPredict_seq = invert_normalize_0_1(testPredict_seq)

DC = np.mean(validation[:,0])
testPredict_seq = validation[:,0]-DC
IPython.display.Audio(validation[:,0], rate=fs)

DC = np.mean(validation[:,1])
testPredict_seq = validation[:,1]-DC
IPython.display.Audio(validation[:,1], rate=fs)

DC = np.mean(testPredict_seq)
testPredict_seq = testPredict_seq-DC
IPython.display.Audio(np.squeeze(np.array(testPredict_seq)), rate=fs)

#write the three audios into a 3 .wav file
write('trainX.wav', fs, training[:,0])
write('trainY.wav', fs, training[:,1])
write('trainPrediction.wav', fs, np.squeeze(np.array(trainPredict_seq)))

#plot prediction vs target (validation)
plt.figure(figsize=(20,2))
plt.plot(validation[:,0])
plt.figure(figsize=(20,2))
plt.plot(validation[:,1])
plt.figure(figsize=(20,2))
plt.plot(testPredict_seq)
